{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp notebook copy to check the new data release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyllh.core.config import Config\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skyllh.datasets.i3.PublicData_10y_ps import create_dataset_collection\n",
    "from skyllh.datasets.i3.PublicData_14y_ps import create_dataset_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsc = create_dataset_collection(\n",
    "    cfg=cfg, \n",
    "    base_path='/data/user/tkontrimas/datarelease_2025/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dsc['IC40', 'IC59', 'IC79', 'IC86_I-XI']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis used for the published PRL results is referred in SkyLLH as \"*traditional point-source analysis*\" and is pre-defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyllh.analyses.i3.publicdata_ps.time_integrated_ps import create_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyllh.core.source_model import PointLikeSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source = PointLikeSource(ra=np.deg2rad(77.35), dec=np.deg2rad(5.7)) # TXS\n",
    "\n",
    "source = PointLikeSource(ra=np.deg2rad(40.67), dec=np.deg2rad(-0.01)) # NGC1068"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 43/43 [00:03<00:00, 13.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 43/43 [00:02<00:00, 15.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 43/43 [00:03<00:00, 13.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 43/43 [00:03<00:00, 14.07it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:24<00:00,  6.04s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 176/176 [00:00<00:00, 7134.48it/s]\n"
     ]
    }
   ],
   "source": [
    "ana = create_analysis(cfg=cfg, datasets=datasets, source=source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyllh.core.random import RandomStateService\n",
    "rss = RandomStateService(seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ts, x, status) = ana.unblind(minimizer_rss=rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS = 29.922\n",
      "ns = 79.38\n",
      "gamma = 3.11\n"
     ]
    }
   ],
   "source": [
    "print(f'TS = {ts:.3f}')\n",
    "print(f'ns = {x[\"ns\"]:.2f}')\n",
    "print(f'gamma = {x[\"gamma\"]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the corresponding flux normalization "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the analysis is created with a flux normalization of 1 GeV$^{-1}$s$^{-1}$cm$^{-2}$sr$^{-1}$ (see `refplflux_Phi0` argument of the `create_analysis` method). The analysis instance has the method `calculate_fluxmodel_scaling_factor` that calculates the scaling factor the reference flux normalization has to be multiplied with to represent a given analysis result, i.e. $n_{\\text{s}}$ and $\\gamma$ value. This function takes the detected mean $n_{\\text{s}}$ value as first argument and the list of source parameter values as second argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flux scaling factor = 2.751e-14\n"
     ]
    }
   ],
   "source": [
    "scaling_factor = ana.calculate_fluxmodel_scaling_factor(x['ns'], [x['ns'], x['gamma']])\n",
    "print(f'Flux scaling factor = {scaling_factor:.3e}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, our result corresponds to a power-law flux of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.751e-14 (E/1000 GeV)^{-3.11} 1/(GeV s cm^2 sr)\n"
     ]
    }
   ],
   "source": [
    "print(f'{scaling_factor:.3e}'' (E/1000 GeV)^{-'f'{x[\"gamma\"]:.2f}'+'} 1/(GeV s cm^2 sr)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the log-likelihood ratio function\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is useful to be able to evaluate the log-likelihood ratio function, e.g. for creating a likelihood contour plot. Because SkyLLH's structure is based on the mathematical structure of the likelihood function, the `Analysis` instance has the property `llhratio` which is the class instance of the used log-likelihood ratio function. This instance has the method `evaluate`. The method takes an array of the fit parameter values as argument at which the LLH ratio function will be evaluated. It returns the value of the LLH ratio function at the given point and its gradients w.r.t. the fit parameters.\n",
    "\n",
    "In our case this is the number of signal events, $n_{\\mathrm{s}}$ and the spectral index $\\gamma$. If we evaluate the LLH ratio function at the maximum, the gradients should be close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ana.llhratio.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(llhratio_value, (grad_ns, grad_gamma)) = ana.llhratio.evaluate([14.58, 2.17])\n",
    "print(f'llhratio_value = {llhratio_value:.3f}')\n",
    "print(f'grad_ns = {grad_ns:.3f}')\n",
    "print(f'grad_gamma = {grad_gamma:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `evaluate` method of the `LLHRatio` class we can scan the log-likelihood ratio space and create a contour plot showing the best fit and the 68%, 90%, and 95% quantile assuming Wilks-theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ns_min, ns_max, ns_step) = (0, 80, 0.5)\n",
    "(gamma_min, gamma_max, gamma_step) = (1.5, 4.0, 0.1)\n",
    "\n",
    "ns_edges = np.linspace(ns_min, ns_max, int((ns_max-ns_min)/ns_step)+1)\n",
    "ns_vals = 0.5*(ns_edges[1:] + ns_edges[:-1])\n",
    "\n",
    "gamma_edges = np.linspace(gamma_min, gamma_max, int((gamma_max-gamma_min)/gamma_step+1))\n",
    "gamma_vals = 0.5*(gamma_edges[1:] + gamma_edges[:-1])\n",
    "\n",
    "delta_ts = np.empty((len(ns_vals), len(gamma_vals)), dtype=np.double)\n",
    "for (ns_i, ns) in enumerate(ns_vals):\n",
    "    for (gamma_i, gamma) in enumerate(gamma_vals):\n",
    "\n",
    "        delta_ts[ns_i, gamma_i] = (\n",
    "            ana.calculate_test_statistic(llhratio_value, [14.58, 2.17]) -\n",
    "            ana.calculate_test_statistic(ana.llhratio.evaluate([ns, gamma])[0], [ns, gamma])\n",
    "        )\n",
    "\n",
    "# Determine the best fit ns and gamma values from the scan.\n",
    "index_max = np.argmin(delta_ts)\n",
    "ns_i_max = int(index_max / len(gamma_vals))\n",
    "gamma_i_max = index_max % len(gamma_vals)\n",
    "ns_best = ns_vals[ns_i_max]\n",
    "gamma_best = gamma_vals[gamma_i_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the delta lambda value for the 95% quantile assuming a chi-sqaure\n",
    "# distribution with 2 degrees of freedom (i.e. assuming Wilks theorem).\n",
    "chi2_68_quantile = scipy.stats.chi2.ppf(0.68, df=2)\n",
    "chi2_90_quantile = scipy.stats.chi2.ppf(0.90, df=2)\n",
    "chi2_95_quantile = scipy.stats.chi2.ppf(0.95, df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.pcolormesh(gamma_edges, ns_edges, delta_ts, cmap='nipy_spectral')\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(r'$\\Delta$TS')\n",
    "plt.contour(gamma_vals, ns_vals, delta_ts, [chi2_68_quantile], colors='#FFFFFF')\n",
    "plt.contour(gamma_vals, ns_vals, delta_ts, [chi2_90_quantile], colors='#AAAAAA')\n",
    "plt.contour(gamma_vals, ns_vals, delta_ts, [chi2_95_quantile], colors='#444444')\n",
    "plt.plot(gamma_best, ns_best, marker='x', color='white', ms=10)\n",
    "plt.xlabel(r'$\\gamma$')\n",
    "plt.ylabel(r'$n_{\\mathrm{s}}$')\n",
    "plt.ylim(ns_min, ns_max)\n",
    "plt.xlim(gamma_min, gamma_max)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the significance (local p-value)\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The significance of the source, i.e. the local p-value, can be calculated by generating the test-statistic distribution of background-only data trials, i.e. for zero injected signal events. SkyLLH provides the helper function ``create_trial_data_file`` to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyllh.core.utils.analysis import create_trial_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(create_trial_data_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we will generate 10k trials and look at the test-statistic distribution. We will time the trial generation using the ``TimeLord`` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyllh.core.timing import TimeLord\n",
    "tl = TimeLord()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rss = RandomStateService(seed=1)\n",
    "(_, _, _, trials) = create_trial_data_file(\n",
    "    ana=ana,\n",
    "    rss=rss,\n",
    "    n_trials=1e4,\n",
    "    mean_n_sig=0,\n",
    "    pathfilename='/home/mwolf/projects/publicdata_ps/txs_bkg_trails.npy',\n",
    "    ncpu=8,\n",
    "    tl=tl)\n",
    "print(tl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the background trials, we can histogram the test-statistic values and plot the TS distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(h, be) = np.histogram(trials['ts'], bins=np.arange(0, np.max(trials['ts'])+0.1, 0.1))\n",
    "plt.plot(0.5*(be[:-1]+be[1:]), h, drawstyle='steps-mid', label='background')\n",
    "plt.vlines(ts, 1, np.max(h), label=f'TS(TXS 0506+056)={ts:.3f}')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('TS')\n",
    "plt.ylabel('#trials per bin')\n",
    "plt.legend()\n",
    "pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the TS value of the unblinded data for TXS is rather large and 10k trials are not enough to calculate a reliable estimate for the p-value. Hence, we will generate a few more trials. SkyLLH provides also a helper function to extend the trial data file we just created. It is called ``extend_trial_data_file``: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyllh.core.utils.analysis import extend_trial_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(extend_trial_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = TimeLord()\n",
    "rss = RandomStateService(seed=2)\n",
    "trials = extend_trial_data_file(\n",
    "    ana=ana,\n",
    "    rss=rss,\n",
    "    n_trials=4e4,\n",
    "    trial_data=trials,\n",
    "    pathfilename='/home/mwolf/projects/publicdata_ps/txs_bkg_trails.npy',\n",
    "    ncpu=8,\n",
    "    tl=tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The local p-value is defined as the fraction of background trials with TS value greater than the unblinded TS value of the source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_log10_pval = -np.log10(len(trials[trials['ts'] > ts]) / len(trials))\n",
    "print(f'-log10(p_local) = {minus_log10_pval:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(h, be) = np.histogram(trials['ts'], bins=np.arange(0, np.max(trials['ts'])+0.1, 0.1))\n",
    "plt.plot(0.5*(be[:-1]+be[1:]), h, drawstyle='steps-mid', label='background')\n",
    "plt.vlines(ts, 1, np.max(h), label=f'TS(TXS 0506+056)={ts:.3f}')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('TS')\n",
    "plt.ylabel('#trials per bin')\n",
    "plt.legend()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ana.data_list[0].exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ana.data_list)):\n",
    "    print(ana.data_list[i].exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.concatenate([\n",
    "        np.linspace(-1., -0.75, 10 + 1),\n",
    "        np.linspace(-0.75, 0., 15 + 1),\n",
    "        np.linspace(0., 1., 20 + 1),\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(-1, 1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic79_exp_orig = np.load('/data/ana/analyses/ps_tracks/version-004-p02/IC79_exp.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic79_exp_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_bins = np.arange(1., 9.5 + 0.01, 0.125)\n",
    "\n",
    "plt.hist(ic79_exp_orig['logE'], bins=energy_bins)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
